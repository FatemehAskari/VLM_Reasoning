{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a55b128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📷 Processing: output_images\\11\\trial-11_0.png\n",
      "🔎 Predicted: 13 | Expected: 11\n",
      "📷 Processing: output_images\\11\\trial-11_12.png\n",
      "🔎 Predicted: 14 | Expected: 11\n",
      "📷 Processing: output_images\\11\\trial-11_14.png\n",
      "🔎 Predicted: 13 | Expected: 11\n",
      "📷 Processing: output_images\\11\\trial-11_17.png\n",
      "🔎 Predicted: 11 | Expected: 11\n",
      "📷 Processing: output_images\\11\\trial-11_19.png\n",
      "🔎 Predicted: 13 | Expected: 11\n",
      "📷 Processing: output_images\\11\\trial-11_20.png\n",
      "🔎 Predicted: 13 | Expected: 11\n",
      "📷 Processing: output_images\\11\\trial-11_22.png\n",
      "🔎 Predicted: 15 | Expected: 11\n",
      "📷 Processing: output_images\\11\\trial-11_28.png\n",
      "🔎 Predicted: 14 | Expected: 11\n",
      "📷 Processing: output_images\\11\\trial-11_29.png\n",
      "🔎 Predicted: 13 | Expected: 11\n",
      "📷 Processing: output_images\\11\\trial-11_32.png\n",
      "🔎 Predicted: 13 | Expected: 11\n",
      "📷 Processing: output_images\\12\\trial-12_11.png\n",
      "🔎 Predicted: 14 | Expected: 12\n",
      "📷 Processing: output_images\\12\\trial-12_15.png\n",
      "🔎 Predicted: 14 | Expected: 12\n",
      "📷 Processing: output_images\\12\\trial-12_16.png\n",
      "🔎 Predicted: 13 | Expected: 12\n",
      "📷 Processing: output_images\\12\\trial-12_17.png\n",
      "🔎 Predicted: 13 | Expected: 12\n",
      "📷 Processing: output_images\\12\\trial-12_18.png\n",
      "🔎 Predicted: 12 | Expected: 12\n",
      "📷 Processing: output_images\\12\\trial-12_19.png\n",
      "🔎 Predicted: 15 | Expected: 12\n",
      "📷 Processing: output_images\\12\\trial-12_20.png\n",
      "🔎 Predicted: 15 | Expected: 12\n",
      "📷 Processing: output_images\\12\\trial-12_21.png\n",
      "🔎 Predicted: 15 | Expected: 12\n",
      "📷 Processing: output_images\\12\\trial-12_22.png\n",
      "🔎 Predicted: 15 | Expected: 12\n",
      "📷 Processing: output_images\\12\\trial-12_23.png\n",
      "🔎 Predicted: 14 | Expected: 12\n",
      "📷 Processing: output_images\\13\\trial-13_1.png\n",
      "🔎 Predicted: 15 | Expected: 13\n",
      "📷 Processing: output_images\\13\\trial-13_10.png\n",
      "🔎 Predicted: 15 | Expected: 13\n",
      "📷 Processing: output_images\\13\\trial-13_11.png\n",
      "🔎 Predicted: 14 | Expected: 13\n",
      "📷 Processing: output_images\\13\\trial-13_12.png\n",
      "🔎 Predicted: 13 | Expected: 13\n",
      "📷 Processing: output_images\\13\\trial-13_14.png\n",
      "🔎 Predicted: 15 | Expected: 13\n",
      "📷 Processing: output_images\\13\\trial-13_17.png\n",
      "🔎 Predicted: 15 | Expected: 13\n",
      "📷 Processing: output_images\\13\\trial-13_18.png\n",
      "🔎 Predicted: 15 | Expected: 13\n",
      "📷 Processing: output_images\\13\\trial-13_2.png\n",
      "🔎 Predicted: 15 | Expected: 13\n",
      "📷 Processing: output_images\\13\\trial-13_20.png\n",
      "🔎 Predicted: 15 | Expected: 13\n",
      "📷 Processing: output_images\\13\\trial-13_22.png\n",
      "🔎 Predicted: 15 | Expected: 13\n",
      "\n",
      "✅ Done! Accuracy: 10.00% (3/30)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import re\n",
    "from pathlib import Path\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# === LangChain Model Setup ===\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.avalai.ir/v1\",\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=\"aa-IbxIACL4oknjL1lneG03Cgum5IrWc0PGV5KyH8JwU3At7yj3\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# === Helper Functions ===\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "def invoke_llm_with_image(test_image_path, example_image_path):\n",
    "    test_base64 = encode_image(test_image_path)\n",
    "    example_base64 = encode_image(example_image_path)\n",
    "    test_ext = Path(test_image_path).suffix[1:]\n",
    "    example_ext = Path(example_image_path).suffix[1:]  # ✅ fixed\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \n",
    "                    \"\"\"\n",
    "🎯 **Task:**  \n",
    "Count the total number of circles in the image.  \n",
    "The image includes visible horizontal and vertical rulers (with coordinate labels) to help you navigate the image.\n",
    "\n",
    "You should use these rulers to **systematically scan the image**, moving left to right, top to bottom, based on the coordinate ticks.\n",
    "\n",
    "---\n",
    "\n",
    "🧭 **Scan Strategy:**\n",
    "\n",
    "1. Start at the top-left corner of the image (e.g., coordinate (0, 0)).\n",
    "2. Move left to right along the x-axis, using the tick marks as column boundaries (e.g., every 70 pixels).\n",
    "3. Once a row is done, move down to the next row along the y-axis (e.g., every 100 pixels).\n",
    "4. Repeat until the entire image has been scanned.\n",
    "\n",
    "---\n",
    "\n",
    "🧠 **Rules for Circle Counting:**\n",
    "\n",
    "- **Majority Area Rule:**  \n",
    "If a circle overlaps multiple regions, count it only once — in the region where most of its area lies.\n",
    "- **No Double Counting:**  \n",
    "Never count a circle more than once.\n",
    "- **Multiple Circles:**  \n",
    "The image may contain multiple circles — some regions might have more than one.\n",
    "\n",
    "---\n",
    "\n",
    "📋 **Output Format:**  \n",
    "Simply return:\n",
    "\n",
    "**Total Number of Circles:** _N_\n",
    "\n",
    "---\n",
    "\n",
    "🖼️ **Example Image:**  \n",
    "The image below shows an example with coordinate rulers and some circles. Analyze it and provide the total number of circles.\n",
    "                    \"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/{example_ext};base64,{example_base64}\",\n",
    "                        \"detail\": \"auto\",\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \n",
    "                    \"\"\"\n",
    "✅ **Example Output:**\n",
    "\n",
    "**Total Number of Circles:** 12\n",
    "\n",
    "---\n",
    "\n",
    "Now analyze the following test image in the same way and provide only the total number of circles:\n",
    "                    \"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/{test_ext};base64,{test_base64}\",\n",
    "                        \"detail\": \"auto\",\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Please count the total number of circles in the image using the coordinate rulers as a guide. Only return the final total count.\"\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    ai_response = llm.invoke(messages)\n",
    "    return ai_response.content\n",
    "\n",
    "def extract_total_count(text):\n",
    "    match = re.search(r\"\\*\\*Total Number of Circles:\\*\\*\\s*([0-9]+)\", text)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "# === Main Processing ===\n",
    "input_root = \"output_images\"\n",
    "example_image_path = \"output_images/12/trial-12_18.png\"\n",
    "results = []\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for folder_name in os.listdir(input_root):\n",
    "    folder_path = os.path.join(input_root, folder_name)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        true_count = int(folder_name)\n",
    "    except ValueError:\n",
    "        print(f\"Skipping folder {folder_name}, not a number.\")\n",
    "        continue\n",
    "\n",
    "    image_files = sorted([\n",
    "        f for f in os.listdir(folder_path)\n",
    "        if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "    ])[:10]  # ✅ Only take first 10 images\n",
    "\n",
    "    for filename in image_files:\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        print(f\"📷 Processing: {image_path}\")\n",
    "\n",
    "        try:\n",
    "            response_text = invoke_llm_with_image(image_path, example_image_path)\n",
    "            predicted_count = extract_total_count(response_text)\n",
    "\n",
    "            print(f\"🔎 Predicted: {predicted_count} | Expected: {true_count}\")\n",
    "\n",
    "            correct_prediction = predicted_count == true_count\n",
    "            result = {\n",
    "                \"image\": image_path,\n",
    "                \"true_count\": true_count,\n",
    "                \"predicted_count\": predicted_count,\n",
    "                \"correct\": correct_prediction,\n",
    "                \"raw_response\": response_text\n",
    "            }\n",
    "\n",
    "            results.append(result)\n",
    "            total += 1\n",
    "            if correct_prediction:\n",
    "                correct += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {image_path}: {e}\")\n",
    "\n",
    "# === Save and Report ===\n",
    "accuracy = correct / total if total > 0 else 0.0\n",
    "summary = {\n",
    "    \"accuracy\": accuracy,\n",
    "    \"total\": total,\n",
    "    \"correct\": correct,\n",
    "    \"results\": results\n",
    "}\n",
    "\n",
    "with open(\"gpt4o_counting_accuracy_report.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n✅ Done! Accuracy: {accuracy:.2%} ({correct}/{total})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
